package br.com.gabrieldev.ecommercelog.service;

import br.com.gabrieldev.ecommercelog.domain.dto.LogDTO;
import br.com.gabrieldev.ecommercelog.domain.mapper.LogMapper;
import br.com.gabrieldev.ecommercelog.domain.type.LogType;
import br.com.gabrieldev.ecommercelog.repository.LogRepository;
import br.com.gabrieldev.ecommercelog.util.DateUtil;
import lombok.RequiredArgsConstructor;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.stereotype.Service;
import br.com.gabrieldev.ecommercelog.domain.entity.Log;

import java.time.LocalDateTime;


/**
 * This class holds all methods needed to register logs on our database
 *
 * @author Gabriel Guimar達es de Almeida
 * */
@Service
@RequiredArgsConstructor
public class LogService {

    private final LogMapper logMapper;
    private final LogRepository logRepository;

    /**
     * This method receive two strings as param, the message's topic and body, and use it to build a log and save it
     * on our database
     *
     * @param topic {@link String} message's topic
     * @param body {@link String} message's body
     *
     * @author Gabriel Guimar達es de Almeida
     * */
    public LogDTO save(String topic, String body){
        var savedLog = logRepository.save(logMapper.toEntity(topic, body));
        return logMapper.toDTO(savedLog);
    }

    /**
     * This method receive a {@link LogDTO} as param and parse it to {@link Log} and save it on our database
     *
     * @param logDTO {@link LogDTO} data to be parsed
     *
     * @author Gabriel Guimar達es de Almeida
     * */
    public LogDTO save(LogDTO logDTO){
        logRepository.save(logMapper.toEntity(logDTO));
        return logDTO;
    }

    /**
     * This method creates the research log and filter all logs on database by the param values and returns it
     * @param topic: {@link String} log's topic, it has a value when the log was generated by a kafka message
     * @param type: {@link LogType} log's type, it can be "MESSAGE", when the log was generated by a kafka message,
     *           or "SEARCH", when the log was generated by research on database.
     * @param initialDate: {@link String} search period's start
     * @param finalDate: {@link String} search period's end
     * @param pageable : {@link Pageable} values those will dictate how much data will be returned
     *
     * @return <{@link Page}<{@link LogDTO}>>: Page with the filtered data
     * @author Gabriel Guimar達es de Almeida
     * */
    public Page<LogDTO> filter(Pageable pageable, String topic, LogType type, String initialDate, String finalDate) {
        save(buildSearchLog(pageable, topic, type, initialDate, finalDate));
        return logRepository.filter(
                topic, type, DateUtil.parseDateFromString(initialDate), DateUtil.parseDateFromString(finalDate), pageable
        ).map(logMapper::toDTO);
    }

    private LogDTO buildSearchLog(Pageable pageable, String topic, LogType type, String initialDate, String finalDate) {
        var toSave = new LogDTO(
                "",
                String.format(
                        "Search by: topic: %s; type: %s; initial date: %s; final date: %s; pageable: %s",
                        topic, type, initialDate, finalDate, pageable.toString()
                ),
                LogType.SEARCH,
                LocalDateTime.now()
        );
        return toSave;
    }
}
